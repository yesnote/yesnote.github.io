---
layout: single
title:  "[PyTorch for Deep Learning] 01 PyTorch Workflow - 2. Build Model"
categories: [Deep Learning]
tag: [pytorch, coding, deeplearning]
use_math: true
---

이 글은 PyTorch workflow 공부에 관한 기록입니다.


# Build model 

Our first PyTorch model!

This is very exciting... let's do it!

Because we're going to be building classes throughout the course, I'd recommend getting familiar with OOP in Python, to do so you can use the following resource from [Real Python](https://realpython.com/python3-object-oriented-programming/){: target="_blank"}

What our model does:
* Start with random values (weight & bias)
* Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight & bias values we used to create the data)

How does it do so?

Through two main algorithms:
1. [Gradient descent](https://youtu.be/IHZwWFHWa-w){: target="_blank"}
2. [Backpropagation](https://youtu.be/Ilg3gGewQ5U){: target="_blank"}

--> 학습이란: andom한 Value로부터 시작해서 (Weight & Bias) 우리가 준비한 데이터의 패턴을 정확히 표현할 수 있도록 근사화하는 과정


```python
from torch import nn

# Create linear regression model class
class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch inherhits from nn.Module
  def __init__(self):
    super().__init__()
    self.weights = nn.Parameter(torch.randn(1, # <- start with a random weight and try to adjust it to the ideal weight
                                            requires_grad=True, # <- can this parameter be updated via gradient descent?
                                            dtype=torch.float)) # <- PyTorch loves the datatype torch.float32
    
    self.bias = nn.Parameter(torch.randn(1, # <- start with a random bias and try to adjust it to the ideal bias
                                         requires_grad=True, # <- can this parameter be updated via gradient descent?
                                         dtype=torch.float)) # <- PyTorch loves the datatype torch.float32 
    
  # Forward method to define the computation in the model
  def forward(self, x: torch.Tensor) -> torch.Tensor: # <- "x" is the input data
    return self.weights * x + self.bias # this is the linear regression formula
```

--> LinearRegressionModel이란 이름의 class를 생성하는 과정이며, nn.Module을 subclass로 가집니다.

--> `def __init__(self): super().__init()__`: class를 생성할 때 사용하는 하나의 신택스 정도로 생각하면 될 것 같습니다. --> 정확히 무슨 의미인지 파악할 필요

--> self.weights, self.bias 변수 생성하고, forward 함수 정의를 필수적으로 해야합니다.

## PyTorch model building essentials

* torch.nn - contains all of the buildings for computational graphs (a neural network can be considered a computational graph)
* torch.nn.Parameter - what parameters should our model try and learn, often a PyTorch layer from torch.nn will set these for us 
* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should overwrite forward()
* torch.optim - this where the optimizers in PyTorch live, they will help with gradient descent
* def forward() - All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation 

See more of these essential modules via the [PyTorch cheatsheet](https://pytorch.org/tutorials/beginner/ptcheat.html ){: target="_blank"}

--> PyTorch cheatsheet은 신이다...

## Checking the contents of our PyTorch model

Now we've created a model, let's see what's inside...

So we can check our model parameters or what's inside our model using `.parameters()`.


```python
# Create a random seed
torch.manual_seed(42)

# Create an instance of the model (this is a subclass of nn.Module)
model_0 = LinearRegressionModel()

# Check out the parameters
list(model_0.parameters())
```




    [Parameter containing:
     tensor([0.3367], requires_grad=True), Parameter containing:
     tensor([0.1288], requires_grad=True)]




```python
# List named parameters
model_0.state_dict()
```




    OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])

--> .parameters() 혹은 .state_dict() 이 두개로 파라미터 파악이 쉽게 가능합니다.



## Making prediction using `torch.inference_mode()`

To check our model's predictive power, let's see how well it predicts `y_test` based on `X_test`.

When we pass data through our model, it's going to run it through the `forward()` method.

--> 학습한 모델의 Prediction을 확인하고 싶을 때, 또는 Test하고 싶을 때 꼭 `with torch.inference_mode()` 를 사용해야 합니다.

--> 코드를 실행할 때 그래디언트 추적을 중지시킵니다.


```python
y_preds = model_0(X_test)
y_preds
```




    tensor([[0.3982],
            [0.4049],
            [0.4116],
            [0.4184],
            [0.4251],
            [0.4318],
            [0.4386],
            [0.4453],
            [0.4520],
            [0.4588]], grad_fn=<AddBackward0>)




```python
# Make predictions with model
with torch.inference_mode():
  y_preds = model_0(X_test)
  

# # You can also do something similar with torch.no_grad(), however, torch.inference_mode() is preferred
# with torch.no_grad():
#   y_preds = model_0(X_test)

y_preds
```




    tensor([[0.3982],
            [0.4049],
            [0.4116],
            [0.4184],
            [0.4251],
            [0.4318],
            [0.4386],
            [0.4453],
            [0.4520],
            [0.4588]])



```python
y_test
```




    tensor([[0.8600],
            [0.8740],
            [0.8880],
            [0.9020],
            [0.9160],
            [0.9300],
            [0.9440],
            [0.9580],
            [0.9720],
            [0.9860]])




```python
plot_predictions(predictions=y_preds)
```


    
![01_pytorch_workflow_video_23_0](https://github.com/yesnote/yesnote.github.io/assets/173476188/46a4bcf0-30fe-431b-8001-a78160719658)